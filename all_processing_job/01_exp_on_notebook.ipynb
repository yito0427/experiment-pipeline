{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. データサイエンティストによるノートブックでの試行錯誤\n",
    "\n",
    "データが蓄積され取得できるようになったら、データサイエンティストはEDA（探索的データ解析）を行い、モデルを構築し、評価します。\n",
    "本ノートブックでは、データサイエンティストによるモデル構築コードを提示します。\n",
    "以降のノートブックで、作成されたスクリプトのモジュール化を行なっていきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験内容\n",
    "\n",
    "下記のノートブックと同様の実験を行います。\n",
    "\n",
    "https://github.com/aws-samples/aws-ml-jp/blob/main/mlops/step-functions-data-science-sdk/model-train-evaluate-compare/step_functions_mlworkflow_scikit_learn_data_processing_and_model_evaluation_with_experiments.ipynb\n",
    "\n",
    ">このノートブックで使用するデータは Census-Income KDD Dataset です。このデータセットから特徴量を選択し、データクレンジングを実施し、二値分類モデルの利用できる形にデータを変換し、最後にデータを学習用とテスト用に分割します。このノートブックではロジスティック回帰モデルを使って、国勢調査の回答者の収入が 5万ドル以上か 5万ドル未満かを予測します。このデータセットはクラスごとの不均衡が大きく、ほとんどのデータに 5万ドル以下というラベルが付加されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提：データは事前に dataset/ に手動で格納しておく\n",
    "\n",
    "データを以下のサイトから入手し、 dataset ディレクトリに配置してください。\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29\n",
    "\n",
    "./dataset/census-income.csv(101.5MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データサイエンティストによる、モデル構築\n",
    "データサイエンティストがEDAを行なったあと、ノートブック上でモデルの構築、評価を行なった場合を想定します。\n",
    "\n",
    "このスクリプトでは、以下の処理が実行されます。\n",
    "\n",
    "* 重複データやコンフリクトしているデータの削除\n",
    "* ターゲット変数 income 列をカテゴリ変数から 2つのラベルを持つ列に変換\n",
    "* age と num persons worked for employer をビニングして数値からカテゴリ変数に変換\n",
    "* 連続値であるcapital gains, capital losses, dividends from stocks を学習しやすいようスケーリング\n",
    "* education, major industry code, class of workerを学習しやすいようエンコード\n",
    "* データを学習用とテスト用に分割し特徴量とラベルの値をそれぞれ保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コードの詳細\n",
    "\n",
    "以下、69行（空行含む）\n",
    "* ライブラリ読み込み：7行\n",
    "* 空行：9行\n",
    "* コメント：11行\n",
    "* コード実行：19行\n",
    "* コード実行の改行：23行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the latest sagemaker, stepfunctions and boto3 SDKs\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -qU pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "### データ読み込み\n",
    "columns = [\n",
    "    \"age\",\n",
    "    \"education\",\n",
    "    \"major industry code\",\n",
    "    \"class of worker\",\n",
    "    \"num persons worked for employer\",\n",
    "    \"capital gains\",\n",
    "    \"capital losses\",\n",
    "    \"dividends from stocks\",\n",
    "    \"income\",\n",
    "]\n",
    "class_labels = [\" - 50000.\", \" 50000+.\"]\n",
    "\n",
    "df = pd.read_csv(\"./dataset/census-income.csv\")\n",
    "df = df[columns]\n",
    "\n",
    "### 前処理\n",
    "#重複データやコンフリクトしているデータの削除\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.replace(class_labels, [0, 1], inplace=True)\n",
    "\n",
    "#ターゲット変数 income 列をカテゴリ変数から 2つのラベルを持つ列に変換\n",
    "negative_examples, positive_examples = np.bincount(df[\"income\"])\n",
    "#データを学習用とテスト用に分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"income\", axis=1), df[\"income\"], test_size=0.2)\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    #age と num persons worked for employer をビニングして数値からカテゴリ変数に変換\n",
    "    (\n",
    "        KBinsDiscretizer(encode=\"onehot-dense\", n_bins=10),\n",
    "        [\"age\", \"num persons worked for employer\"],\n",
    "    ),\n",
    "    #連続値であるcapital gains, capital losses, dividends from stocks を学習しやすいようスケーリング\n",
    "    (\n",
    "        StandardScaler(),\n",
    "        [\"capital gains\", \"capital losses\", \"dividends from stocks\"],\n",
    "    ),\n",
    "    #education, major industry code, class of workerを学習しやすいようエンコード\n",
    "    (\n",
    "        OneHotEncoder(sparse=False, handle_unknown='ignore'),\n",
    "        [\"education\", \"major industry code\", \"class of worker\"],\n",
    "    ),\n",
    ")\n",
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.transform(X_test)\n",
    "\n",
    "### 学習\n",
    "model = LogisticRegression(class_weight=\"balanced\", solver=\"lbfgs\", C=float(1.0), verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "### 推論\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "### 評価\n",
    "report_dict = classification_report(y_test, predictions, output_dict=True)\n",
    "report_dict[\"accuracy\"] = accuracy_score(y_test, predictions)\n",
    "report_dict[\"roc_auc\"] = roc_auc_score(y_test, predictions)\n",
    "print(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ノートブックのインタラクティブ性は、EDAやモデルプロトタイプなどの初期の試行錯誤には大変便利です。\n",
    "一方で、モジュール化されていないコードや記録されていないコードや、本番運用を見据えると、後のコード本番化、リファクタリングなどの工数を増加や、テストの難しさによる品質確保が難しいといった懸念もあります。\n",
    "\n",
    "試行錯誤の柔軟性を確保しつつ、モジュール化されたコードをきちんと記録していくことが、コードの品質向上と、本番導入の迅速化には重要になります。\n",
    "以降のノートブックでは、実験を支援するパイプラインを準備し、ノートブックをモジュール化していく例をみていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [参考] 詰め込んだ場合、以下の23行で完了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "df = pd.read_csv(\"./dataset/census-income.csv\")\n",
    "df = df[[\"age\",\"education\",\"major industry code\",\"class of worker\",\"num persons worked for employer\",\"capital gains\",\"capital losses\",\"dividends from stocks\",\"income\",]]\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.replace([\" - 50000.\", \" 50000+.\"], [0, 1], inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"income\", axis=1), df[\"income\"], test_size=0.2)\n",
    "preprocess = make_column_transformer((KBinsDiscretizer(encode=\"onehot-dense\", n_bins=10),[\"age\", \"num persons worked for employer\"],),(StandardScaler(),[\"capital gains\", \"capital losses\", \"dividends from stocks\"],),(OneHotEncoder(sparse=False, handle_unknown='ignore'),[\"education\", \"major industry code\", \"class of worker\"],),)\n",
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.transform(X_test)\n",
    "model = LogisticRegression(class_weight=\"balanced\", solver=\"lbfgs\", C=float(1.0), verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "report_dict = classification_report(y_test, predictions, output_dict=True)\n",
    "report_dict[\"accuracy\"] = accuracy_score(y_test, predictions)\n",
    "report_dict[\"roc_auc\"] = roc_auc_score(y_test, predictions)\n",
    "print(report_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
